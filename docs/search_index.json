[["17-TARST.html", "17 Temas adicionales en la regresión de series temporales", " 17 Temas adicionales en la regresión de series temporales Este capítulo analiza los siguientes temas avanzados en la regresión de series de tiempo y demuestra cómo se pueden aplicar las técnicas básicas usando R: Autorregresiones vectoriales (VAR). Se enfoca en usar VAR para pronosticar. Otra rama de la literatura se ocupa de los llamados VAR estructurales, que están más allá del alcance de este capítulo. Previsiones multiperiodo. Esto incluye una discusión de pronósticos iterados y directos (multivariados). La prueba DF-GLS, una modificación de la prueba ADF que tiene más potencia que esta última cuando la serie tiene componentes deterministas y está cerca de ser no estacionaria. Análisis de cointegración con aplicación a tipos de interés a corto y largo plazo. Se demuestra cómo estimar un modelo de corrección de errores vectoriales. Modelos de Heterocedasticidad condicional autorregresiva (ARCH). Se muestra cómo un modelo ARCH generalizado simple (GARCH) puede ser útil para cuantificar el riesgo asociado con la inversión en el mercado de valores en términos de estimación y pronóstico de la volatilidad de los rendimientos de los activos. Para reproducir los ejemplos de código, se necesita instalar los paquetes R que se enumeran a continuación. Asegúrese que el siguiente fragmento de código se ejecute sin errores. AER (Kleiber and Zeileis 2020) dynlm (Zeileis 2019) fGarch (Wuertz et al. 2020) quantmod (Ryan and Ulrich 2020) readxl (Wickham and Bryan 2019) scales (Wickham and Seidel 2020) vars (Pfaff 2018) library(AER) library(readxl) library(dynlm) library(vars) library(quantmod) library(scales) library(fGarch) Referencias bibliográficas "],["17-1-autorregresiones-vectoriales.html", "17.1 Autorregresiones vectoriales", " 17.1 Autorregresiones vectoriales Un modelo de Vector autorregresivo (VAR) es útil cuando se está interesado en predecir múltiples variables de series de tiempo usando un solo modelo. En esencia, el modelo VAR es una extensión del modelo autorregresivo univariante que se ha tratado en los capítulos 15 y 16. El concepto clave 16.1 resume los fundamentos del VAR. Concepto clave 16.1 Autoregresiones vectoriales El modelo de autorregresión vectorial (VAR) extiende la idea de autorregresión univariante a regresiones de series de tiempo \\(k\\), donde los valores rezagados de todas \\(k\\) series aparecen como regresores. Dicho de otra manera, en un modelo VAR se hace una regresión de un vector de variables de series de tiempo en vectores rezagados de estas variables. En cuanto a los modelos AR (\\(p\\)), el orden de retraso se denota por \\(p\\) por lo que el modelo VAR (\\(p\\)) de dos variables \\(X_t\\) y \\(Y_t\\) (\\(k = 2\\)) viene dado por las ecuaciones: \\[\\begin{align*} Y_t =&amp; \\, \\beta_{10} + \\beta_{11} Y_{t-1} + \\dots + \\beta_{1p} Y_{t-p} + \\gamma_{11} X_{t-1} + \\dots + \\gamma_{1p} X_{t-p} + u_{1t}, \\\\ X_t =&amp; \\, \\beta_{20} + \\beta_{21} Y_{t-1} + \\dots + \\beta_{2p} Y_{t-p} + \\gamma_{21} X_{t-1} + \\dots + \\gamma_{2p} X_{t-p} + u_{2t}. \\end{align*}\\] Los \\(\\beta\\)s y \\(\\gamma\\)s se pueden estimar usando MCO en cada ecuación. Los supuestos para los VAR son los supuestos de series de tiempo presentados en el Concepto clave 14.6 aplicados a cada una de las ecuaciones. Es sencillo estimar modelos VAR en R. Un enfoque factible es simplemente usar lm() para la estimación de las ecuaciones individuales. Además, el paquete R vars proporciona herramientas estándar para estimación, pruebas de diagnóstico y predicción utilizando este tipo de modelos. Cuando se cumplen los supuestos del Concepto clave 16.1, los estimadores MCO de los coeficientes VAR son consistentes y conjuntamente normales en muestras grandes, de modo que se pueden utilizar los métodos inferenciales habituales, como los intervalos de confianza y los estadísticos \\(t\\). La estructura de los VAR también permite probar conjuntamente las restricciones en múltiples ecuaciones. Por ejemplo, puede ser de interés probar si los coeficientes de todos los regresores del rezago \\(p\\) son cero. Esto corresponde a probar el nulo de que el orden de retraso \\(p-1\\) es correcto. La normalidad conjunta de muestras grandes de las estimaciones de coeficientes es conveniente porque implica que simplemente se puede usar una prueba \\(F\\) para este problema de prueba. La fórmula explícita para un estadístico de prueba de este tipo es bastante complicada, pero afortunadamente estos cálculos se realizan fácilmente utilizando las funciones R con las que se trabaja en este capítulo. Otra forma de determinar las longitudes de retraso óptimas son los criterios de información como \\(BIC\\) que se ha introducido para las regresiones de series de tiempo univariadas en el Capítulo 15.6. Al igual que en el caso de una sola ecuación, para un modelo de ecuaciones múltiples se elige la especificación que tiene el menor \\(BIC(p)\\), donde \\[\\begin{align*} BIC(p) =&amp; \\, \\log\\left[\\text{det}(\\widehat{\\Sigma}_u)\\right] + k(kp+1) \\frac{\\log(T)}{T}. \\end{align*}\\] donde \\(\\widehat{\\Sigma}_u\\) denota la estimación de la matriz de covarianza \\(k \\times k\\) de los errores VAR y \\(\\text{det}(\\cdot)\\) denota el determinante. En cuanto a los modelos de rezagos distribuidos univariados, se debe pensar detenidamente en las variables que se incluirán en un VAR, ya que agregar variables no relacionadas reduce la precisión del pronóstico al aumentar el error de estimación. Esto es particularmente importante porque el número de parámetros a estimar crece cuadráticamente al número de variables modeladas por el VAR. En la aplicación siguiente se verá que la teoría económica y la evidencia empírica son útiles para esta decisión. Un modelo VAR de la tasa de crecimiento del PIB y el margen temporal Ahora se muestra cómo estimar un modelo VAR de la tasa de crecimiento del PIB, \\(GDPGR\\), y el diferencial de plazo, \\(TSpread\\). Como sigue la discusión sobre la no estacionariedad del crecimiento del PIB en el Capítulo 15.7 (recuerde la posible ruptura a principios de la década de 1980 detectada por la estadística de prueba \\(QLR\\)), se usan datos de 1981:Q1 a 2012:Q4. Las dos ecuaciones del modelo son \\[\\begin{align*} GDPGR_t =&amp; \\, \\beta_{10} + \\beta_{11} GDPGR_{t-1} + \\beta_{12} GDPGR_{t-2} + \\gamma_{11} TSpread_{t-1} + \\gamma_{12} TSpread_{t-2} + u_{1t}, \\\\ TSpread_t =&amp; \\, \\beta_{20} + \\beta_{21} GDPGR_{t-1} + \\beta_{22} GDPGR_{t-2} + \\gamma_{21} TSpread_{t-1} + \\gamma_{22} TSpread_{t-2} + u_{2t}. \\end{align*}\\] El conjunto de datos us_macro_quarterly.xlsx se proporciona en el sitio web complementario a Stock and Watson (2015) y se puede descargar aquí. Contiene datos trimestrales sobre el PIB real de EE. UU. (es decir, ajustado a la inflación) de 1947 a 2004. Se comienza importando el conjunto de datos y aplicando un formato (ya se trabajó con este conjunto de datos en el Capítulo 15, por lo que se pueden omitir estos pasos si ya se han cargado los datos en el entorno de trabajo). # cargar el conjunto de datos macroeconómicos de EE. UU. USMacroSWQ &lt;- read_xlsx(&quot;data/us_macro_quarterly.xlsx&quot;, sheet = 1, col_types = c(&quot;text&quot;, rep(&quot;numeric&quot;, 9))) # establecer los nombres de las columnas colnames(USMacroSWQ) &lt;- c(&quot;Date&quot;, &quot;GDPC96&quot;, &quot;JAPAN_IP&quot;, &quot;PCECTPI&quot;, &quot;GS10&quot;, &quot;GS1&quot;, &quot;TB3MS&quot;, &quot;UNRATE&quot;, &quot;EXUSUK&quot;, &quot;CPIAUCSL&quot;) # formatear la columna de fecha USMacroSWQ$Date &lt;- as.yearqtr(USMacroSWQ$Date, format = &quot;%Y:0%q&quot;) # definir el PIB como objeto ts GDP &lt;- ts(USMacroSWQ$GDPC96, start = c(1957, 1), end = c(2013, 4), frequency = 4) # definir el crecimiento del PIB como un objeto ts GDPGrowth &lt;- ts(400*log(GDP[-1]/GDP[-length(GDP)]), start = c(1957, 2), end = c(2013, 4), frequency = 4) # tasa de interés de las letras del Tesoro a 3 meses como objeto &#39;ts&#39; TB3MS &lt;- ts(USMacroSWQ$TB3MS, start = c(1957, 1), end = c(2013, 4), frequency = 4) # tasa de interés de los bonos del Tesoro a 10 años como objeto &#39;ts&#39; TB10YS &lt;- ts(USMacroSWQ$GS10, start = c(1957, 1), end = c(2013, 4), frequency = 4) # generar la serie diferencial por plazo TSpread &lt;- TB10YS - TB3MS Se estiman ambas ecuaciones por separado por MCO y se usa coeftest() para obtener errores estándar robustos. # estimar ambas ecuaciones usando &#39;dynlm()&#39; VAR_EQ1 &lt;- dynlm(GDPGrowth ~ L(GDPGrowth, 1:2) + L(TSpread, 1:2), start = c(1981, 1), end = c(2012, 4)) VAR_EQ2 &lt;- dynlm(TSpread ~ L(GDPGrowth, 1:2) + L(TSpread, 1:2), start = c(1981, 1), end = c(2012, 4)) # cambiar el nombre de los regresores para una mejor legibilidad names(VAR_EQ1$coefficients) &lt;- c(&quot;Intercept&quot;, &quot;Growth_t-1&quot;, &quot;Growth_t-2&quot;, &quot;TSpread_t-1&quot;, &quot;TSpread_t-2&quot;) names(VAR_EQ2$coefficients) &lt;- names(VAR_EQ1$coefficients) # resúmenes robustos de coeficientes coeftest(VAR_EQ1, vcov. = sandwich) #&gt; #&gt; t test of coefficients: #&gt; #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; Intercept 0.516344 0.524429 0.9846 0.3267616 #&gt; Growth_t-1 0.289553 0.110827 2.6127 0.0101038 * #&gt; Growth_t-2 0.216392 0.085879 2.5197 0.0130255 * #&gt; TSpread_t-1 -0.902549 0.358290 -2.5190 0.0130498 * #&gt; TSpread_t-2 1.329831 0.392660 3.3867 0.0009503 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 coeftest(VAR_EQ2, vcov. = sandwich) #&gt; #&gt; t test of coefficients: #&gt; #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; Intercept 0.4557740 0.1214227 3.7536 0.0002674 *** #&gt; Growth_t-1 0.0099785 0.0218424 0.4568 0.6485920 #&gt; Growth_t-2 -0.0572451 0.0264099 -2.1676 0.0321186 * #&gt; TSpread_t-1 1.0582279 0.0983750 10.7571 &lt; 2.2e-16 *** #&gt; TSpread_t-2 -0.2191902 0.1086198 -2.0180 0.0457712 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Se termina con los siguientes resultados: \\[\\begin{align*} GDPGR_t =&amp; \\, \\underset{(0.46)}{0.52} + \\underset{(0.11)}{0.29} GDPGR_{t-1} + \\underset{(0.09)}{0.22} GDPGR_{t-2} -\\underset{(0.36)}{0.90} TSpread_{t-1} + \\underset{(0.39)}{1.33} TSpread_{t-2} \\\\ TSpread_t =&amp; \\, \\underset{(0.12)}{0.46} + \\underset{(0.02)}{0.01} GDPGR_{t-1} -\\underset{(0.03)}{0.06} GDPGR_{t-2} + \\underset{(0.10)}{1.06} TSpread_{t-1} -\\underset{(0.11)}{0.22} TSpread_{t-2} \\end{align*}\\] La función VAR() se puede utilizar para obtener las mismas estimaciones de coeficientes que se presentaron anteriormente, ya que también se aplica MCO por ecuación. # configurar datos para la estimación usando `VAR()` VAR_data &lt;- window(ts.union(GDPGrowth, TSpread), start = c(1980, 3), end = c(2012, 4)) # estimar los coeficientes del modelo usando `VAR()` VAR_est &lt;- VAR(y = VAR_data, p = 2) VAR_est #&gt; #&gt; VAR Estimation Results: #&gt; ======================= #&gt; #&gt; Estimated coefficients for equation GDPGrowth: #&gt; ============================================== #&gt; Call: #&gt; GDPGrowth = GDPGrowth.l1 + TSpread.l1 + GDPGrowth.l2 + TSpread.l2 + const #&gt; #&gt; GDPGrowth.l1 TSpread.l1 GDPGrowth.l2 TSpread.l2 const #&gt; 0.2895533 -0.9025493 0.2163919 1.3298305 0.5163440 #&gt; #&gt; #&gt; Estimated coefficients for equation TSpread: #&gt; ============================================ #&gt; Call: #&gt; TSpread = GDPGrowth.l1 + TSpread.l1 + GDPGrowth.l2 + TSpread.l2 + const #&gt; #&gt; GDPGrowth.l1 TSpread.l1 GDPGrowth.l2 TSpread.l2 const #&gt; 0.009978489 1.058227945 -0.057245123 -0.219190243 0.455773969 VAR() devuelve una lista de objetos lm que se pueden pasar a las funciones habituales, por ejemplo summary() y, por lo tanto, es sencillo obtener estadísticas del modelo para el ecuaciones individuales. # obtener el R^2 ajustado de la salida de &#39;VAR()&#39; summary(VAR_est$varresult$GDPGrowth)$adj.r.squared #&gt; [1] 0.2887223 summary(VAR_est$varresult$TSpread)$adj.r.squared #&gt; [1] 0.8254311 Se pueden utilizar los objetos del modelo individual para realizar pruebas de causalidad de Granger. # Pruebas de causalidad de Granger: # probar si el diferencial de plazo no tiene poder para explicar el crecimiento del PIB linearHypothesis(VAR_EQ1, hypothesis.matrix = c(&quot;TSpread_t-1&quot;, &quot;TSpread_t-2&quot;), vcov. = sandwich) #&gt; Linear hypothesis test #&gt; #&gt; Hypothesis: #&gt; TSpread_t - 0 #&gt; TSpread_t - 2 = 0 #&gt; #&gt; Model 1: restricted model #&gt; Model 2: GDPGrowth ~ L(GDPGrowth, 1:2) + L(TSpread, 1:2) #&gt; #&gt; Note: Coefficient covariance matrix supplied. #&gt; #&gt; Res.Df Df F Pr(&gt;F) #&gt; 1 125 #&gt; 2 123 2 5.9094 0.003544 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # probar si el crecimiento del PIB no tiene poder para explicar el diferencial de plazo linearHypothesis(VAR_EQ2, hypothesis.matrix = c(&quot;Growth_t-1&quot;, &quot;Growth_t-2&quot;), vcov. = sandwich) #&gt; Linear hypothesis test #&gt; #&gt; Hypothesis: #&gt; Growth_t - 0 #&gt; Growth_t - 2 = 0 #&gt; #&gt; Model 1: restricted model #&gt; Model 2: TSpread ~ L(GDPGrowth, 1:2) + L(TSpread, 1:2) #&gt; #&gt; Note: Coefficient covariance matrix supplied. #&gt; #&gt; Res.Df Df F Pr(&gt;F) #&gt; 1 125 #&gt; 2 123 2 3.4777 0.03395 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Ambas pruebas de causalidad de Granger se rechazan al nivel de \\(5\\%\\). Esto es evidencia a favor de la conjetura de que el diferencial por plazo tiene poder para explicar el crecimiento del PIB y viceversa. Pronósticos multivariados iterados usando un VAR iterado La idea de un pronóstico iterado para el período \\(T + 2\\) basado en observaciones hasta el período \\(T\\) es utilizar el pronóstico de un período adelantado como paso intermedio; es decir, el pronóstico para el período \\(T + 1\\) se usa como una observación al predecir el nivel de una serie para el período \\(T + 2\\). Esto se puede generalizar a un pronóstico de \\(h\\) para el período futuro en el que todos los períodos intermedios entre \\(T\\) y \\(T + h\\) deben pronosticarse, ya que se utilizan como observaciones en el proceso. Los pronósticos iterados de múltiples períodos se resumen en el Concepto clave 16.2. Concepto clave 16.2 Pronósticos de varios períodos iterados Los pasos para un pronóstico de RA iterado de varios períodos son: Estimar el modelo AR (\\(p\\)) usando MCO y calcular el pronóstico de un período adelantado. Utilizar el pronóstico de un período adelantado para obtener el pronóstico de dos períodos adelante. Continuar iterando para obtener pronósticos más lejanos en el futuro. Un pronóstico VAR iterado de múltiples períodos se realiza de la siguiente manera: Estimar el modelo VAR (\\(p\\)) usando MCO por ecuación y calcular el pronóstico de un período adelantado para todas las variables en el VAR. Utilizar los pronósticos de un período por delante para obtener los pronósticos de dos períodos adelante. Continuar iterando para obtener pronósticos de todas las variables en el VAR en el futuro. Dado que un VAR modela todas las variables usando rezagos de las otras variables respectivas, se necesitan calcular pronósticos para todas las variables. Puede resultar engorroso hacerlo cuando el VAR es grande, pero afortunadamente existen funciones R que facilitan esto. Por ejemplo, la función predict() se puede utilizar para obtener pronósticos multivariados iterados para modelos VAR estimados por la función VAR(). El siguiente fragmento de código muestra cómo calcular pronósticos iterados para el crecimiento del PIB y el diferencial por plazo hasta el período 2015:Q1, que es \\(h = 10\\), utilizando el objeto modelo VAR_est. # calcular pronósticos iterados para el crecimiento del PIB y el diferencial por plazo para los próximos 10 trimestres forecasts &lt;- predict(VAR_est) forecasts #&gt; $GDPGrowth #&gt; fcst lower upper CI #&gt; [1,] 1.738653 -3.006124 6.483430 4.744777 #&gt; [2,] 1.692193 -3.312731 6.697118 5.004925 #&gt; [3,] 1.911852 -3.282880 7.106583 5.194731 #&gt; [4,] 2.137070 -3.164247 7.438386 5.301317 #&gt; [5,] 2.329667 -3.041435 7.700769 5.371102 #&gt; [6,] 2.496815 -2.931819 7.925449 5.428634 #&gt; [7,] 2.631849 -2.846390 8.110088 5.478239 #&gt; [8,] 2.734819 -2.785426 8.255064 5.520245 #&gt; [9,] 2.808291 -2.745597 8.362180 5.553889 #&gt; [10,] 2.856169 -2.722905 8.435243 5.579074 #&gt; #&gt; $TSpread #&gt; fcst lower upper CI #&gt; [1,] 1.676746 0.708471226 2.645021 0.9682751 #&gt; [2,] 1.884098 0.471880228 3.296316 1.4122179 #&gt; [3,] 1.999409 0.336348101 3.662470 1.6630609 #&gt; [4,] 2.080836 0.242407507 3.919265 1.8384285 #&gt; [5,] 2.131402 0.175797245 4.087008 1.9556052 #&gt; [6,] 2.156094 0.125220562 4.186968 2.0308738 #&gt; [7,] 2.161783 0.085037834 4.238528 2.0767452 #&gt; [8,] 2.154170 0.051061544 4.257278 2.1031082 #&gt; [9,] 2.138164 0.020749780 4.255578 2.1174139 #&gt; [10,] 2.117733 -0.007139213 4.242605 2.1248722 Esto revela que el pronóstico de dos trimestres de crecimiento del PIB en 2013:Q2 utilizando datos hasta 2012:Q4 es \\(1.69\\). Para el mismo período, el pronóstico de VAR iterado para el diferencial de plazo es \\(1.88\\). Las matrices devueltas por predict(VAR_est) también incluyen intervalos de predicción de \\(95\\%\\) (sin embargo, la función no se ajusta para la autocorrelación o heterocedasticidad de los errores). También se pueden trazar los pronósticos iterados para ambas variables llamando a plot() en la salida de predict(VAR_est). # visualizar los pronósticos iterados plot(forecasts) Pronósticos directos para múltiples períodos Un pronóstico directo de múltiples períodos utiliza un modelo en el que los predictores se retrasan de manera adecuada, de modo que las observaciones disponibles se puedan usar directamente para realizar el pronóstico. La idea de la predicción directa de varios períodos se resume en el Concepto clave 16.3. Concepto clave 16.3 Pronósticos directos para múltiples períodos Un pronóstico directo para períodos múltiples que pronostica períodos de \\(h\\) en el futuro utilizando un modelo de \\(Y_t\\) y un predictor adicional \\(X_t\\) con retrasos de \\(p\\) se realiza estimando primero: \\[\\begin{align*} Y_t =&amp; \\, \\delta_0 + \\delta_1 Y_{t-h} + \\dots + \\delta_{p} Y_{t-p-h+1} + \\delta_{p+1} X_{t-h} \\\\ +&amp; \\dots + \\delta_{2p} Y_{t-p-h+1} + u_t, \\end{align*}\\] que luego se usa para calcular el pronóstico de \\(Y_{T + h}\\) basado en observaciones durante el período \\(T\\). Por ejemplo, para obtener previsiones de dos trimestres de crecimiento del PIB y el margen de plazo, primero se estiman las ecuaciones: \\[\\begin{align*} GDPGR_t =&amp; \\, \\beta_{10} + \\beta_{11} GDPGR_{t-2} + \\beta_{12} GDPGR_{t-3} + \\gamma_{11} TSpread_{t-2} + \\gamma_{12} TSpread_{t-3} + u_{1t}, \\\\ TSpread_t =&amp; \\, \\beta_{20} + \\beta_{21} GDPGR_{t-2} + \\beta_{22} GDPGR_{t-3} + \\gamma_{21} TSpread_{t-2} + \\gamma_{22} TSpread_{t-3} + u_{2t} \\end{align*}\\] y luego se sustituyen los valores de \\(GDPGR_{2012:Q4}\\), \\(GDPGR_{2012:Q3}\\), \\(TSpread_{2012:Q4}\\) y \\(TSpread_{2012:Q3}\\) en ambas ecuaciones. Esto se hace fácilmente de forma manual. # modelos de estimación para pronósticos directos a dos trimestres VAR_EQ1_direct &lt;- dynlm(GDPGrowth ~ L(GDPGrowth, 2:3) + L(TSpread, 2:3), start = c(1981, 1), end = c(2012, 4)) VAR_EQ2_direct &lt;- dynlm(TSpread ~ L(GDPGrowth, 2:3) + L(TSpread, 2:3), start = c(1981, 1), end = c(2012, 4)) # calcular pronósticos directos a dos trimestres coef(VAR_EQ1_direct) %*% c(1, # intercepto window(GDPGrowth, start = c(2012, 3), end = c(2012, 4)), window(TSpread, start = c(2012, 3), end = c(2012, 4))) #&gt; [,1] #&gt; [1,] 2.439497 coef(VAR_EQ2_direct) %*% c(1, # intercepto window(GDPGrowth, start = c(2012, 3), end = c(2012, 4)), window(TSpread, start = c(2012, 3), end = c(2012, 4))) #&gt; [,1] #&gt; [1,] 1.66578 Los economistas aplicados a menudo usan el método iterado, ya que estos pronósticos son más confiables en términos de \\(MSFE\\), siempre que el modelo de un período adelantado se especifique correctamente. Si este no es el caso, por ejemplo, porque se cree que una ecuación en un VAR está mal especificada, puede ser beneficioso usar pronósticos directos, ya que el método iterado estará sesgado y, por lo tanto, tendrá un \\(MSFE\\) más alto que el método directo. Consulte el Capítulo 17.2 para obtener una discusión más detallada sobre las ventajas y desventajas de ambos métodos. Referencias bibliográficas "],["17-2-OIPRUDFGLS.html", "17.2 Órdenes de integración y prueba de raíz unitaria DF-GLS", " 17.2 Órdenes de integración y prueba de raíz unitaria DF-GLS Algunas series de tiempo económicas tienen tendencias más suaves que las variables que pueden describirse mediante modelos de recorridos aleatorios. Una forma de modelar estas series de tiempo es \\[\\Delta Y_t = \\beta_0 + \\Delta Y_{t-1} + u_t,\\] donde \\(u_t\\) es un término de error no correlacionado en serie. Este modelo establece que la primera diferencia de una serie es un paseo aleatorio. En consecuencia, la serie de segundas diferencias de \\(Y_t\\) es estacionaria. El Concepto clave 16.4 resume la notación. Concepto clave 16.4 Órdenes de integración, diferenciación y estacionariedad Cuando una serie de tiempo \\(Y_t\\) tiene una raíz autorregresiva unitaria, \\(Y_t\\) se integra de orden uno. Esto a menudo se denota por \\(Y_t \\sim I(1)\\). Simplemente se dice que \\(Y_t\\) es \\(I(1)\\). Si \\(Y_t\\) es \\(I(1)\\), su primera diferencia \\(\\Delta Y_t\\) es estacionaria. \\(Y_t\\) es \\(I(2)\\) cuando \\(Y_t\\) necesita diferenciarse dos veces para obtener una serie estacionaria. Usando la notación presentada aquí, si \\(Y_t\\) es \\(I(2)\\), su primera diferencia \\(\\Delta Y_t\\) es \\(I(1)\\) y su segunda diferencia \\(\\Delta^2 Y_t\\) es estacionaria. \\(Y_t\\) es \\(I(d)\\) cuando \\(Y_t\\) debe diferenciarse \\(d\\) veces para obtener una serie estacionaria. Cuando \\(Y_t\\) es estacionario, se integra del orden \\(0\\) por lo que \\(Y_t\\) es \\(I(0)\\). Es bastante fácil obtener diferencias de series de tiempo en R. Por ejemplo, la función diff() devuelve diferencias adecuadamente rezagadas e iteradas de vectores numéricos, matrices y objetos de series de tiempo de la clase ts. Se toma el nivel de precios de los EE. UU. Medido por el Índice de precios de gastos de consumo personal como ejemplo. # definir el objeto ts del índice de precios PCE de EE. UU. PCECTPI &lt;- ts(log(USMacroSWQ$PCECTPI), start = c(1957, 1), end = c(2012, 4), freq = 4) # graficar logaritmo del índice de precios de PCE plot(log(PCECTPI), main = &quot;Logaritmo del índice de precios PCE de Estados Unidos&quot;, ylab = &quot;Logaritmo&quot;, col = &quot;steelblue&quot;, lwd = 2) El logaritmo del nivel de precios tiene una tendencia que varía suavemente. Esto es típico de una serie \\(I(2)\\). Si el nivel de precios es realmente \\(I(2)\\), las primeras diferencias de esta serie deberían ser \\(I(1)\\). Dado que se está considerando el logaritmo del nivel de precios, se obtienen tasas de crecimiento tomando las primeras diferencias. Por lo tanto, la serie de niveles de precios diferenciados es la serie de tasas de inflación trimestrales. Esto se hace rápidamente en R usando la función Delt() del paquete quantmod. Como se explica en el Capítulo 15.2, al multiplicar las tasas de inflación trimestrales por \\(400\\) se obtiene la tasa de inflación trimestral, medida en puntos porcentuales a una tasa anual. # graficar la inflación de precios del PCE de EE. UU. plot(400 * Delt(PCECTPI), main = &quot;United States PCE Price Index&quot;, ylab = &quot;Porcentaje por año&quot;, col = &quot;steelblue&quot;, lwd = 2) # agregar una línea discontinua en y = 0 abline(0, 0, lty = 2) La tasa de inflación se comporta de manera mucho más errática que el gráfico uniforme del logaritmo del índice de precios del PCE. La prueba DF-GLS para una raíz unitaria La prueba DF-GLS para una raíz unitaria ha sido desarrollada por Elliott, Rothenberg, and Stock (1996) y tiene mayor potencia que la prueba ADF cuando la raíz autorregresiva es grande, pero menor que uno; es decir, el DF-GLS tiene una mayor probabilidad de rechazar el falso nulo de una tendencia estocástica cuando los datos de la muestra provienen de una serie de tiempo que está cerca de integrarse. La idea de la prueba DF-GLS es probar una raíz unitaria autorregresiva en la serie sin tendencia, mediante la cual las estimaciones de GLS de los componentes deterministas se utilizan para obtener la versión sin tendencia de la serie original. Una función que realiza la prueba DF-GLS se implementa en el paquete urca (este paquete es una dependencia del paquete vars, por lo que ya debería estar cargado si se adjunta vars). La función que calcula la estadística de prueba es ur.ers. # prueba DF-GLS para raíz unitaria en el PIB summary(ur.ers(log(window(GDP, start = c(1962, 1), end = c(2012, 4))), model = &quot;trend&quot;, lag.max = 2)) #&gt; #&gt; ############################################### #&gt; # Elliot, Rothenberg and Stock Unit Root Test # #&gt; ############################################### #&gt; #&gt; Test of type DF-GLS #&gt; detrending of series with intercept and trend #&gt; #&gt; #&gt; Call: #&gt; lm(formula = dfgls.form, data = data.dfgls) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.025739 -0.004054 0.000017 0.004619 0.033620 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; yd.lag -0.01213 0.01012 -1.199 0.23207 #&gt; yd.diff.lag1 0.28583 0.07002 4.082 6.47e-05 *** #&gt; yd.diff.lag2 0.19320 0.07058 2.737 0.00676 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.007807 on 198 degrees of freedom #&gt; Multiple R-squared: 0.1504, Adjusted R-squared: 0.1376 #&gt; F-statistic: 11.69 on 3 and 198 DF, p-value: 4.392e-07 #&gt; #&gt; #&gt; Value of test-statistic is: -1.1987 #&gt; #&gt; Critical values of DF-GLS are: #&gt; 1pct 5pct 10pct #&gt; critical values -3.48 -2.89 -2.57 El resumen de la prueba muestra que el estadístico de la prueba es de aproximadamente \\(-1.2\\). El valor crítico de $10% $ para la prueba DF-GLS es \\(-2.57\\). Sin embargo, este no es el valor crítico apropiado para la prueba ADF cuando se incluyen una intersección y una tendencia temporal en la regresión de Dickey-Fuller: ¡Las distribuciones asintóticas de ambas estadísticas de prueba difieren y también sus valores críticos! La prueba es del lado izquierdo, por lo que no se puede rechazar la hipótesis nula de que la inflación de EE. UU. no es estacionaria, utilizando la prueba DF-GLS. Referencias bibliográficas "],["17-3-cointegración.html", "17.3 Cointegración", " 17.3 Cointegración Concepto clave 16.5 Cointegration Cuando \\(X_t\\) y \\(Y_t\\) son \\(I(1)\\) y si existe un \\(\\theta\\) tal que \\(Y_t - \\theta X_t\\) es \\(I(0)\\), \\(X_t\\) y \\(Y_t\\) están cointegrados. Dicho de otra manera, la cointegración de \\(X_t\\) y \\(Y_t\\) significa que \\(X_t\\) y \\(Y_t\\) tienen la misma tendencia estocástica o una común y que esta tendencia puede eliminarse tomando una diferencia específica de la serie de modo que la serie resultante sea estacionario. Las funciones R para el análisis de cointegración se implementan en el paquete urca. Como ejemplo, se reconsidera la relación entre las tasas de interés a corto y largo plazo con el ejemplo de las letras del Tesoro de EE. UU. a 3 meses, los bonos del Tesoro de EE. UU. a 10 años y el diferencial en sus tasas de interés que se han introducido en el Capítulo 15.4. El siguiente fragmento de código muestra cómo crear el gráfico. # graficar ambas series de interés plot(merge(as.zoo(TB3MS), as.zoo(TB10YS)), plot.type = &quot;single&quot;, lty = c(2, 1), lwd = 2, xlab = &quot;Fecha&quot;, ylab = &quot;Porcentaje por año&quot;, ylim = c(-5, 17), main = &quot;Tasas de interés&quot;) # agregar la serie de diferencial por plazo lines(as.zoo(TSpread), col = &quot;steelblue&quot;, lwd = 2, xlab = &quot;Fecha&quot;, ylab = &quot;Porcentaje por año&quot;, main = &quot;Diferencial por plazo&quot;) # sombrear el diferencial por plazo polygon(c(time(TB3MS), rev(time(TB3MS))), c(TB10YS, rev(TB3MS)), col = alpha(&quot;steelblue&quot;, alpha = 0.3), border = NA) # agregar línea horizontal agregar 0 abline(0, 0) # agregar una leyenda legend(&quot;topright&quot;, legend = c(&quot;TB3MS&quot;, &quot;TB10YS&quot;, &quot;Diferencial por plazo&quot;), col = c(&quot;black&quot;, &quot;black&quot;, &quot;steelblue&quot;), lwd = c(2, 2, 2), lty = c(2, 1, 1)) El gráfico sugiere que las tasas de interés a largo y a corto plazo están cointegradas: Ambas series de intereses parecen tener el mismo comportamiento a largo plazo. Comparten una tendencia estocástica común. El diferencial de plazo, que se obtiene tomando la diferencia entre las tasas de interés de largo y corto plazo, parece estacionario. De hecho, la teoría de expectativas de la estructura de términos sugiere que el coeficiente de cointegración \\(\\theta\\) es 1. Esto es consistente con el resultado visual. Pruebas de cointegración Siguiendo el Concepto clave 16.5, parece natural construir una prueba para la cointegración de dos series de la siguiente manera: Si dos series \\(X_t\\) y \\(Y_t\\) están cointegradas, la serie obtenida tomando la diferencia \\(Y_t - \\theta X_t\\) debe ser estacionario. Si las series no están cointegradas, \\(Y_t - \\theta X_t\\) no es estacionaria. Esta es una suposición que se puede probar mediante una prueba de raíz unitaria. Se tiene que distinguir entre dos casos: \\(\\theta\\) es conocido. El conocimiento de \\(\\theta\\) permite calcular las diferencias \\(z_t = Y_t - \\theta X_t\\) para que las pruebas de raíz unitaria de Dickey-Fuller y DF-GLS se puedan aplicar a \\(z_t\\). Para estas pruebas, los valores críticos son los valores críticos de la prueba ADF o DF-GLS. \\(\\theta\\) es desconocido. Si se desconoce \\(\\theta\\), debe estimarse antes de que se pueda aplicar la prueba de raíz unitaria. Esto se hace estimando la regresión \\[Y_t = \\alpha + \\theta X_t + z_t\\] usando MCO (esto se conoce como la regresión de la primera etapa). Luego, se usa una prueba de Dickey-Fuller para probar la hipótesis de que \\(z_t\\) es una serie no estacionaria. Esto se conoce como prueba Engle-Granger Augmented Dickey-Fuller para cointegración (o prueba EG-ADF) después de Engle and Granger (1987). Los valores críticos para esta prueba son especiales, ya que la distribución nula asociada no es normal y depende del número de variables \\(I(1)\\) utilizadas como regresores en la regresión de la primera etapa. Cuando solo existen dos variables presuntamente cointegradas (y, por lo tanto, se usa una sola variable \\(I(1)\\) en la regresión de MCO de la primera etapa), los valores críticos para los niveles $10% $, \\(5\\%\\) y \\(1\\%\\) son \\(-3.12\\), \\(-3.41\\) y \\(-3.96\\). Aplicación a las tasas de interés Como se mencionó anteriormente, la teoría de la estructura temporal sugiere que las tasas de interés a largo y corto plazo están cointegradas con un coeficiente de cointegración de \\(\\theta = 1\\). En la sección anterior se ha visto que existe evidencia visual de esta conjetura, ya que el diferencial de las tasas de interés a 10 años y a 3 meses parece estacionario. Se continua usando pruebas formales (la ADF y la prueba DF-GLS) para ver si las series de tasas de interés individuales están integradas y si su diferencia es estacionaria (por ahora, se asume que se conoce \\(\\theta = 1\\)). Ambos se hacen convenientemente usando las funciones ur.df() para el cálculo de la prueba ADF y ur.ers() para realizar la prueba DF-GLS. Se usan datos desde 1962:Q1 hasta 2012:Q4 y se emplean modelos que incluyen un término de deriva. Se establece el orden de retraso máximo en \\(6\\) y se usa \\(AIC\\) para seleccionar la longitud de retraso óptima. # prueba de no estacionariedad de letras del tesoro a 3 meses usando la prueba ADF ur.df(window(TB3MS, c(1962, 1), c(2012, 4)), lags = 6, selectlags = &quot;AIC&quot;, type = &quot;drift&quot;) #&gt; #&gt; ############################################################### #&gt; # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -2.1004 2.2385 # prueba de no estacionariedad de bonos del tesoro a 10 años usando la prueba ADF ur.df(window(TB10YS, c(1962, 1), c(2012, 4)), lags = 6, selectlags = &quot;AIC&quot;, type = &quot;drift&quot;) #&gt; #&gt; ############################################################### #&gt; # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -1.0079 0.5501 # prueba de no estacionariedad de letras del tesoro a 3 meses usando la prueba DF-GLS ur.ers(window(TB3MS, c(1962, 1), c(2012, 4)), model = &quot;constant&quot;, lag.max = 6) #&gt; #&gt; ############################################################### #&gt; # Elliot, Rothenberg and Stock Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -1.8042 # prueba de no estacionariedad de bonos del tesoro a 10 años utilizando la prueba DF-GLS ur.ers(window(TB10YS, c(1962, 1), c(2012, 4)), model = &quot;constant&quot;, lag.max = 6) #&gt; #&gt; ############################################################### #&gt; # Elliot, Rothenberg and Stock Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -0.942 El valor crítico correspondiente de \\(10\\%\\) para ambas pruebas es \\(-2.57\\), por lo que no se puede rechazar las hipótesis nulas de no estacionario para ninguna de las series, incluso en el nivel de significancia de \\(10\\%\\).1 Se concluye que es plausible modelar ambas series de tasas de interés como \\(I(1)\\). A continuación, se aplica la prueba ADF y DF-GLS para probar la no estacionariedad de la serie de márgenes de plazo, lo que significa que se prueba la no cointegración de las tasas de interés a corto y largo plazo. # probar si el diferencial de plazo es estacionario (cointegración de tasas de interés) usando ADF ur.df(window(TB10YS, c(1962, 1), c(2012, 4)) - window(TB3MS, c(1962, 1), c(2012 ,4)), lags = 6, selectlags = &quot;AIC&quot;, type = &quot;drift&quot;) #&gt; #&gt; ############################################################### #&gt; # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -3.9308 7.7362 # probar si el diferencial de plazo es estacionario (cointegración de las tasas de interés) utilizando la prueba DF-GLS ur.ers(window(TB10YS, c(1962, 1), c(2012, 4)) - window(TB3MS, c(1962, 1), c(2012, 4)), model = &quot;constant&quot;, lag.max = 6) #&gt; #&gt; ############################################################### #&gt; # Elliot, Rothenberg and Stock Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -3.8576 La Tabla 17.1 resume los resultados. Table 17.1: Estadísticos de prueba ADF y DF-GLS para series de tipos de interés Series Estadístic0 de prueba ADF Estadístico de prueba DF-GLS TB3MS \\(-2.10\\) \\(-1.80\\) TB10YS \\(-1.01\\) \\(-0.94\\) TB10YS - TB3MS \\(-3.93\\) \\(-3.86\\) Ambas pruebas rechazan la hipótesis de no estacionariedad de la serie de diferenciales por plazo en el nivel de significancia de \\(1\\%\\), lo que constituye una fuerte evidencia a favor de la hipótesis de que el diferencial de plazos es estacionario, lo que implica la cointegración de las tasas de interés de largo y corto plazo. Dado que la teoría sugiere que \\(\\theta=1\\), no existe necesidad de estimar \\(\\theta\\), por lo que no es necesario utilizar la prueba EG-ADF que permite que \\(\\theta\\) sea desconocido. Sin embargo, dado que es instructivo hacerlo, se calcula este estadístico de prueba. La regresión MCO de la primera etapa es \\[TB10YS_t = \\beta_0 + \\beta_1 TB3MS_t + z_t.\\] # estimar la regresión de la primera etapa de la prueba EG-ADF FS_EGADF &lt;- dynlm(window(TB10YS, c(1962, 1), c(2012, 4)) ~ window(TB3MS, c(1962, 1), c(2012, 4))) FS_EGADF #&gt; #&gt; Time series regression with &quot;ts&quot; data: #&gt; Start = 1962(1), End = 2012(4) #&gt; #&gt; Call: #&gt; dynlm(formula = window(TB10YS, c(1962, 1), c(2012, 4)) ~ window(TB3MS, #&gt; c(1962, 1), c(2012, 4))) #&gt; #&gt; Coefficients: #&gt; (Intercept) window(TB3MS, c(1962, 1), c(2012, 4)) #&gt; 2.4642 0.8147 Así se tiene que: \\[\\begin{align*} \\widehat{TB10YS}_t = 2.46 + 0.81 \\cdot TB3MS_t, \\end{align*}\\] donde \\(\\widehat{\\theta} = 0.81\\). A continuación, se toma la serie residual \\(\\{\\widehat{z_t}\\}\\) y se calcula el estadístico de prueba ADF. # calcular los residuos z_hat &lt;- resid(FS_EGADF) # calcular el estadístico de prueba ADF ur.df(z_hat, lags = 6, type = &quot;none&quot;, selectlags = &quot;AIC&quot;) #&gt; #&gt; ############################################################### #&gt; # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # #&gt; ############################################################### #&gt; #&gt; The value of the test statistic is: -3.1935 El estadístico de prueba es \\(-3.19\\), que es menor que el valor crítico de \\(10\\%\\), pero mayor que el valor crítico de \\(5\\%\\). Por lo tanto, la hipótesis nula de no cointegración puede rechazarse en el nivel de \\(10\\%\\), pero no en el nivel de \\(5\\%\\). Esto indica una potencia más baja de la prueba EG-ADF debido a la estimación de \\(\\theta\\): Cuando \\(\\theta = 1\\) es el valor correcto, se espera la potencia de la prueba ADF para una raíz unitaria en la serie de residuos = TB10YS - TB3MS$ mayor que cuando se usa una estimación de \\(\\widehat{\\theta}\\). Un modelo de corrección de errores vectoriales para \\(TB10YS_t\\) y \\(TB3MS\\) Si dos \\(I(1)\\) series de tiempo \\(X_t\\) y \\(Y_t\\) están cointegradas, sus diferencias son estacionarias y se pueden modelar en un VAR que se aumenta con el regresor \\(Y_{t-1} - \\theta X_{t-1}\\). Esto se denomina modelo de corrección de errores vectoriales (VECM) y \\(Y_{t} - \\theta X_{t}\\) se denomina término de corrección de errores. Los valores rezagados del término de corrección de errores son útiles para predecir \\(\\Delta X_t\\) y/o \\(\\Delta Y_t\\). Se puede utilizar un VECM para modelar las dos tasas de interés consideradas en las secciones anteriores. Se especifica el VECM para incluir dos rezagos de ambas series como regresores y elegir \\(\\theta = 1\\), como sugiere la teoría (ver arriba). TB10YS &lt;- window(TB10YS, c(1962, 1), c(2012 ,4)) TB3MS &lt;- window(TB3MS, c(1962, 1), c(2012, 4)) # configurar el término de corrección de errores VECM_ECT &lt;- TB10YS - TB3MS # estimar ambas ecuaciones del VECM usando &#39;dynlm()&#39; VECM_EQ1 &lt;- dynlm(d(TB10YS) ~ L(d(TB3MS), 1:2) + L(d(TB10YS), 1:2) + L(VECM_ECT)) VECM_EQ2 &lt;- dynlm(d(TB3MS) ~ L(d(TB3MS), 1:2) + L(d(TB10YS), 1:2) + L(VECM_ECT)) # cambiar el nombre de los regresores para una mejor legibilidad names(VECM_EQ1$coefficients) &lt;- c(&quot;Intercept&quot;, &quot;D_TB3MS_l1&quot;, &quot;D_TB3MS_l2&quot;, &quot;D_TB10YS_l1&quot;, &quot;D_TB10YS_l2&quot;, &quot;ect_l1&quot;) names(VECM_EQ2$coefficients) &lt;- names(VECM_EQ1$coefficients) # resúmenes de coeficientes utilizando errores estándar de HAC coeftest(VECM_EQ1, vcov. = NeweyWest(VECM_EQ1, prewhite = F, adjust = T)) #&gt; #&gt; t test of coefficients: #&gt; #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; Intercept 0.1227089 0.0551419 2.2253 0.027205 * #&gt; D_TB3MS_l1 -0.0016601 0.0727060 -0.0228 0.981807 #&gt; D_TB3MS_l2 -0.0680845 0.0435059 -1.5649 0.119216 #&gt; D_TB10YS_l1 0.2264878 0.0957071 2.3665 0.018939 * #&gt; D_TB10YS_l2 -0.0734486 0.0703476 -1.0441 0.297740 #&gt; ect_l1 -0.0878871 0.0285644 -3.0768 0.002393 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 coeftest(VECM_EQ2, vcov. = NeweyWest(VECM_EQ2, prewhite = F, adjust = T)) #&gt; #&gt; t test of coefficients: #&gt; #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; Intercept -0.060746 0.107937 -0.5628 0.57422 #&gt; D_TB3MS_l1 0.240003 0.111611 2.1504 0.03276 * #&gt; D_TB3MS_l2 -0.155883 0.153845 -1.0132 0.31220 #&gt; D_TB10YS_l1 0.113740 0.125571 0.9058 0.36617 #&gt; D_TB10YS_l2 -0.147519 0.112630 -1.3098 0.19182 #&gt; ect_l1 0.031506 0.050519 0.6236 0.53359 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Por tanto, las dos ecuaciones estimadas del VECM son \\[\\begin{align*} \\widehat{\\Delta TB3MS}_t =&amp; \\, -\\underset{(0.11)}{0.06} + \\underset{(0.11)}{0.24} \\Delta TB3MS_{t-1} -\\underset{(0.15)}{0.16} \\Delta TB3MS_{t-2} \\\\ &amp;+ \\underset{(0.13)}{0.11} \\Delta TB10YS_{t-1} -\\underset{(0.11)}{0.15} \\Delta TB10YS_{t-2} + \\underset{(0.05)}{0.03} ECT_{t-1} \\\\ \\widehat{\\Delta TB10YS}_t =&amp; \\, \\underset{(0.06)}{0.12} -\\underset{(0.07)}{0.00} \\Delta TB3MS_{t-1} -\\underset{(0.04)}{0.07} \\Delta TB3MS_{t-2} \\\\ &amp;+ \\underset{(0.10)}{0.23} \\Delta TB10YS_{t-1} -\\underset{(0.07)}{0.07} \\Delta TB10YS_{t-2} -\\underset{(0.03)}{0.09} ECT_{t-1}. \\end{align*}\\] El resultado producido por coeftest() muestra que existe poca evidencia de que los valores rezagados de la serie de intereses diferenciados sean útiles para la predicción. Este hallazgo es más pronunciado para la ecuación de la serie diferenciada de la tasa de la letra del tesoro a 3 meses, donde el término de corrección de errores (el diferencial de plazo rezagado) no es significativamente diferente de cero en ningún nivel común de significancia. Sin embargo, para la tasa diferenciada de los bonos del tesoro a 10 años, el término de corrección de errores es estadísticamente significativo a \\(1\\%\\) con una estimación de \\(-0.09\\). Esto se puede interpretar de la siguiente manera: Aunque ambas tasas de interés no son estacionarias, su relación de conintegración permite predecir el cambio en la tasa de los bonos del tesoro a 10 años utilizando el VECM. En particular, la estimación negativa del coeficiente del término de corrección de errores indica que habrá un cambio negativo en la tasa de los bonos del tesoro a 10 años del próximo período cuando la tasa de los bonos del tesoro a 10 años sea inusualmente alta en relación con la tasa del tesoro a 3 meses en el período actual. Referencias bibliográficas "],["17-4-agrupación-de-volatilidad-y-heterocedasticidad-condicional-autorregresiva.html", "17.4 Agrupación de volatilidad y heterocedasticidad condicional autorregresiva", " 17.4 Agrupación de volatilidad y heterocedasticidad condicional autorregresiva Las series de tiempo financieras suelen presentar un comportamiento que se conoce como agrupamiento de volatilidad: La volatilidad cambia con el tiempo y su grado muestra una tendencia a persistir; es decir, existen periodos de baja volatilidad y periodos donde la volatilidad es alta. Los econometristas llaman a esto heterocedasticidad condicional autorregresiva. La heterocedasticidad condicional es una propiedad interesante porque puede explotarse para pronosticar la varianza de períodos futuros. Como ejemplo, se consideran los cambios diarios en el índice bursátil Whilshire 5000. Los datos están disponibles para su descarga en la Base de datos económicos de la Reserva Federal. Para mantener la coherencia con el libro, se descargaron los datos desde el 29 de diciembre de 1989 hasta el 31 de diciembre de 2013 (es necesario elegir este intervalo de tiempo algo mayor, ya que más adelante se trabajará con los cambios diarios de la serie). El siguiente fragmento de código muestra cómo formatear los datos y crear un gráfico a partir de ellos. # importar datos del índice Wilshire 5000 W5000 &lt;- read.csv2(&quot;data/Wilshire5000.csv&quot;, stringsAsFactors = F, header = T, sep = &quot;,&quot;, na.strings = &quot;.&quot;) # transformar las columnas W5000$DATE &lt;- as.Date(W5000$DATE) W5000$WILL5000INDFC &lt;- as.numeric(W5000$WILL5000INDFC) # eliminar NAs W5000 &lt;- na.omit(W5000) # calcular cambios porcentuales diarios W5000_PC &lt;- data.frame(&quot;Date&quot; = W5000$DATE, &quot;Value&quot; = as.numeric(Delt(W5000$WILL5000INDFC) * 100)) W5000_PC &lt;- na.omit(W5000_PC) # graficar cambios porcentuales plot(W5000_PC, ylab = &quot;Porcentaje&quot;, main = &quot;Cambios porcentuales diarios&quot;, type=&quot;l&quot;, col = &quot;steelblue&quot;, lwd = 0.5) # agregar una línea horizontal en y = 0 abline(0, 0) (#fig:pcw5000, 914)Rendimientos porcentuales diarios en el índice Wilshire 5000 La serie de cambios porcentuales diarios en el índice de Wilshire parece fluctuar aleatoriamente alrededor de cero, lo que significa que existe poca autocorrelación. Esto se confirma mediante un gráfico de la función de autocorrelación de la muestra. # graficar la autocorrelación de la muestra de los cambios porcentuales diarios acf(W5000_PC$Value, main = &quot;Serie 5000 de Wilshire&quot;) (#fig:acfw5000, 915)Autocorrelación en los cambios diarios de precios del índice W5000 En la Figura ?? se ve que las autocorrelaciones son bastante débiles, por lo que es difícil predecir los resultados futuros utilizando, por ejemplo, un modelo AR. Sin embargo, existe evidencia visual en ?? de que la serie de retornos exhibe heterocedasticidad condicional, ya que se observan agrupaciones de volatilidad. Para algunas aplicaciones, es útil medir y pronosticar estos patrones. Esto se puede hacer utilizando modelos que asumen que la volatilidad puede describirse mediante un proceso autorregresivo. Modelos ARCH y GARCH Considere \\[Y_t = \\beta_0 + \\beta_1 Y_{t-1} + \\gamma_1 X_{t-1} + u_t,\\] un modelo de regresión ADL(\\(1\\),\\(1\\)). El econométrico Robert Engle (1982) propuso modelar \\(\\sigma^2_t = Var(u_t | u_{t-1},u_{t-2},\\ldots)\\), la varianza condicional del error \\(u_t\\) dado su pasado, por un modelo de retraso distribuido de orden \\(p\\), \\[\\begin{align} \\sigma^2_t = \\alpha_0 + \\alpha_1 u_{t-1}^2 + \\alpha_2 u_{t-2}^2 + \\dots + \\alpha_p u_{t-p}^2, \\tag{17.1} \\end{align}\\] llamado modelo de heterocedasticidad condicional autorregresiva (ARCH) de orden \\(p\\), o ARCH corto (\\(p\\)).2 Se supone \\(\\alpha_0&gt;0\\) y \\(\\alpha_1,\\ldots,\\alpha_p\\geq0\\) para asegurar una varianza positiva \\(\\sigma_t^2&gt;0\\). La idea general se desprende de la estructura del modelo: Los coeficientes positivos \\(\\alpha_0,\\alpha_1,\\dots,\\alpha_p\\) implican que los grandes errores cuadrados recientes conducen a una gran varianza y, por lo tanto, a grandes errores cuadrados en el período actual. El modelo ARCH generalizado (GARCH), desarrollado por Tim Bollerslev (1986), es una extensión del modelo ARCH, donde se permite que \\(\\sigma^2_t\\) dependa de sus propios retrasos y de los retrasos del término de error al cuadrado. El modelo GARCH (\\(p\\),\\(q\\)) viene dado por \\[\\begin{align} \\sigma^2_t = \\alpha_0 + \\alpha_1 u_{t-1}^2 + \\alpha_2 u_{t-2}^2 + \\dots + \\alpha_p u_{t-p}^2 + \\phi_1 \\sigma^2_{t-1} + \\dots + \\phi_p \\sigma^2_{t-q}. \\tag{17.2} \\end{align}\\] El modelo GARCH es un modelo ADL (\\(p\\),\\(q\\)) y, por lo tanto, puede proporcionar parametrizaciones más parsimoniosas que el modelo ARCH. Aplicación a la volatilidad del precio de las acciones Las estimaciones de máxima verosimilitud de los modelos ARCH y GARCH son eficientes y tienen distribuciones normales en muestras grandes, de modo que se pueden aplicar los métodos habituales para realizar inferencias sobre los parámetros desconocidos. El paquete fGarch en R consiste en una colección de funciones para analizar y modelar el comportamiento heterocedástico en modelos de series de tiempo. La función garchFit() es algo sofisticada, dado que permite diferentes especificaciones del procedimiento de optimización, diferentes distribuciones de errores y mucho más (use ?GarchFit para una descripción detallada de los argumentos). En particular, los errores estándar reportados por garchFit() son robustos. El modelo GARCH (\\(1\\),\\(1\\)) de cambios diarios en el índice Wilshire 5000 que se estimó viene dado por: \\[\\begin{align} R_t =&amp; \\, \\beta_0 + u_t \\ , \\ u_t \\sim \\mathcal{N}(0,\\sigma^2_t), \\\\ \\sigma^2_t =&amp; \\, \\alpha_0 + \\alpha_1 u_{t-1}^2 + \\phi_1 \\sigma_{t-1}^2 \\tag{17.3} \\end{align}\\] donde \\(R_t\\) es el cambio porcentual en el período \\(t\\). \\(\\beta_0\\), \\(\\alpha_0\\), \\(\\alpha_1\\) y \\(\\phi_1\\) son coeficientes desconocidos y \\(u_t\\) es un término de error con media condicional cero. No se incluyen predictores rezagados en la ecuación de \\(R_t\\) porque los cambios diarios en el índice Wilshire 5000 reflejan rendimientos bursátiles diarios que son esencialmente impredecibles. Se debe tener en cuenta que se supone que \\(u_t\\) tiene una distribución normal y la varianza \\(\\sigma^2_t\\) depende de \\(t\\), ya que sigue la recursividad GARCH (\\(1\\),\\(1\\)) (17.3). Es sencillo estimar este modelo usando garchFit(). # estimar el modelo GARCH (1,1) de cambios porcentuales diarios GARCH_Wilshire &lt;- garchFit(data = W5000_PC$Value, trace = F) Se obtiene: \\[\\begin{align} \\widehat{R}_t =&amp; \\, \\underset{(0.010)}{0.068}, \\tag{17.4} \\\\ \\widehat{\\sigma}^2_t =&amp; \\, \\underset{(0.002)}{0.011} + \\underset{(0.007)}{0.081} u_{t-1}^2 + \\underset{(0.008)}{0.909} \\sigma_{t-1}^2, \\tag{17.5} \\end{align}\\] por lo que los coeficientes en \\(u_{t-1}^2\\) y \\(\\sigma^2_{t-1}\\) son estadísticamente significativos en cualquier nivel común de significancia. Se puede demostrar que la persistencia de movimientos en \\(\\sigma^2_t\\) está determinada por la suma de ambos coeficientes, que aquí es \\(0.99\\). Esto indica que los movimientos en la varianza condicional son muy persistentes, lo que implica períodos prolongados de alta volatilidad, lo que es consistente con la evidencia visual de la agrupación de volatilidad presentada anteriormente. La varianza condicional estimada \\(\\widehat{\\sigma}^2_t\\) se puede calcular conectando los residuos de (17.4) en la ecuación (17.5). Esto lo realiza automáticamente garchFit(), por lo que para obtener las desviaciones estándar condicionales estimadas \\(\\widehat{\\sigma}_t\\) solo se tienen que leer los valores de GARCH_Wilshire agregando \\(\\textit{@sigma.t}\\). Usando \\(\\widehat{\\sigma}_t\\) se grafican bandas de \\(\\pm\\) una desviación estándar condicional junto con las desviaciones de la serie de cambios porcentuales diarios en el índice Wilshire 5000 de su media. El siguiente fragmento de código genera el gráfico. # calcular las desviaciones de los cambios porcentuales de su media dev_mean_W5000_PC &lt;- W5000_PC$Value - GARCH_Wilshire@fit$coef[1] # graficar la desviación de los cambios porcentuales de la media plot(W5000_PC$Date, dev_mean_W5000_PC, type = &quot;l&quot;, col = &quot;steelblue&quot;, ylab = &quot;Porcentaje&quot;, xlab = &quot;Fecha&quot;, main = &quot;Bandas estimadas de + - una desviación estándar condicional&quot;, lwd = 0.2) # agregar una línea horizontal en y = 0 abline(0, 0) # agregar bandas de confianza GARCH(1,1) (una desviación estándar) al gráfico lines(W5000_PC$Date, GARCH_Wilshire@fit$coef[1] + GARCH_Wilshire@sigma.t, col = &quot;darkred&quot;, lwd = 0.5) lines(W5000_PC$Date, GARCH_Wilshire@fit$coef[1] - GARCH_Wilshire@sigma.t, col = &quot;darkred&quot;, lwd = 0.5) Las bandas de las desviaciones estándar condicionales estimadas siguen bastante bien la heterocedasticidad observada en la serie de cambios diarios del índice Wilshire 5000. Esto es útil para cuantificar la volatilidad variable en el tiempo y el riesgo resultante para los inversores que poseen acciones resumidas por el índice. Además, este modelo GARCH también se puede utilizar para producir intervalos de pronóstico cuyos anchos dependen de la volatilidad de los períodos más recientes. Resumen Se ha discutido cómo las autorregresiones vectoriales se estiman convenientemente y se usan para pronosticar en R mediante funciones del paquete vars. El paquete urca proporciona métodos avanzados para el análisis de la raíz unitaria y cointegración como las pruebas DF-GLS y EG-ADF. En una aplicación, se ha encontrado evidencia de que las tasas de interés a 3 meses y 10 años tienen una tendencia estocástica común (es decir, están cointegradas) y, por lo tanto, pueden modelarse utilizando un modelo de corrección de errores vectoriales. Además, se ha introducido el concepto de agrupamiento de volatilidad y demostrado cómo se puede emplear la función garchFit() del paquete fGarch para estimar un modelo GARCH(\\(1\\),\\(1\\)) de la heterocedasticidad condicional inherente a los rendimientos del índice bursátil Wilshire 5000. Referencias bibliográficas "]]
